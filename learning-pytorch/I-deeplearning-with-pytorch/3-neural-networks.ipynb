{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 36px; color: #FFD700\">3 - Neural Networks</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks có thể xây dựng bằng cách sử dụng torch.nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn: Định nghĩa các lớp mạng (models), vd: nn.Linear, nn.Conv2d, ...\n",
    "\n",
    "autograd: Tự động tính gradient, xây dựng compulational graph tự động trong lúc thực thi\n",
    "\n",
    "=> Mối quan hệ: nn định nghĩa kiến trúc mô hình, autograd xử lý quá trình Backward, tính đạo hàm và lưu dúng cho việc cập nhật.\n",
    "\n",
    "    => nn phụ thuộc autograd để có thể trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Một nn.Module sẽ chứa các lớp kiến trúc và một phương thức forward(input) trả về output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ví dụ:\n",
    "\n",
    "<img src=\"https://pytorch.org/tutorials/_images/mnist.png\" alt=\"Ảnh online\" style=\"background-color:white; padding:10px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giải thích từng thuật ngữ & Vai trò cụ thể:\n",
    "- Input - ảnh đưa vào mạng, ở đây là ảnh xám kích thức 32x32 (vd chữ viết tay)\n",
    "- Convolution layer (C1, C3) - Lớp tích chập \n",
    "    - Tác vụ: \n",
    "        - Trích xuất đặc trưng(feature) từ ảnh hoặc feature maps trước đó \n",
    "        - Mỗi filter (kernel) học cách nhận biết các đặc điểm như cạnh, góc, nét cong,...\n",
    "        - Tạo ra feature maps – là biểu diễn không gian các đặc trưng tìm được\n",
    "    Trong LeNet:\n",
    "        - C1: Có 6 filters → 6 feature maps 28x28\n",
    "        - C3: Có 16 filters → 16 feature maps 10x10\n",
    "- Subsampling/ Pooling - Lớp gộp/ giảm mẫu\n",
    "    - Tác vụ:\n",
    "        - Giảm kích thước không gian của feature maps (ví dụ từ 28x28 → 14x14)\n",
    "        - Giúp mạng học nhanh hơn và giảm overfitting\n",
    "        - MaxPooling thường được dùng: chọn giá trị lớn nhất trong mỗi vùng nhỏ\n",
    "    - Trong LeNet:\n",
    "        - S2: 6 feature maps 14x14\n",
    "        - S4: 16 feature maps 5x5\n",
    "- Fully Connected Layers - Lớp kết nối đầy đủ:\n",
    "    - Tác vụ:\n",
    "        - Kết nối toàn bộ các giá trị đặc trưng trước đó với tất cả các neurons tiếp theo\n",
    "        - Thực hiện tổng hợp thông tin toàn cục để chuẩn bị phân loại\n",
    "        - Giống như \"não\" của mạng quyết định ảnh thuộc lớp nào\n",
    "    - Trong LeNet:\n",
    "        - F5: 120 neurons\n",
    "        - F6: 84 neurons\n",
    "- Output layer (10 neural) - Lớp output đầu ra:\n",
    "    - Tác vụ: \n",
    "        - Mỗi neuron tương ứng với một lớp phân loại (ví dụ 0 đến 9 nếu là nhận diện chữ số)\n",
    "        - Sau khi áp dụng Softmax, cho ra xác suất cho từng lớp\n",
    "        - Lớp nào có xác suất cao nhất → là kết quả dự đoán\n",
    " - Feature Maps - Bản đồ đặc trưng\n",
    "    - Tác vụ:\n",
    "        - Là kết quả của mỗi filter khi quét qua ảnh hoặc feature map trước đó\n",
    "        - Cho biết tại vị trí nào trong ảnh đang có đặc trưng cần tìm\n",
    "- Gaussian connections - Kết nối Gaussian\n",
    "    - Tác vụ: Trong LeNet gốc, không phải neuron nào trong lớp fully connected cũng kết nối với tất cả đầu vào. Chỉ kết nối theo mẫu “Gaussian” để tiết kiệm tài nguyên thời đó\n",
    "    - Ngày nay, ta thường dùng full connection thay vì kiểu kết nối này\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
