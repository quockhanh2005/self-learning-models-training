{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 36px; color: #FFD700\">3 - Neural Networks</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks có thể xây dựng bằng cách sử dụng torch.nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn: Định nghĩa các lớp mạng (models), vd: nn.Linear, nn.Conv2d, ...\n",
    "\n",
    "autograd: Tự động tính gradient, xây dựng compulational graph tự động trong lúc thực thi\n",
    "\n",
    "=> Mối quan hệ: nn định nghĩa kiến trúc mô hình, autograd xử lý quá trình Backward, tính đạo hàm và lưu dúng cho việc cập nhật.\n",
    "\n",
    "    => nn phụ thuộc autograd để có thể trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Một nn.Module sẽ chứa các lớp kiến trúc và một phương thức forward(input) trả về output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ví dụ:\n",
    "\n",
    "<img src=\"https://pytorch.org/tutorials/_images/mnist.png\" alt=\"Ảnh online\" style=\"background-color:white; padding:10px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giải thích từng thuật ngữ & Vai trò cụ thể:\n",
    "- `Input` - ảnh đưa vào mạng, ở đây là ảnh xám kích thức 32x32 (vd chữ viết tay)\n",
    "- `Convolution layer` (C1, C3) - Lớp tích chập \n",
    "    - Tác vụ: \n",
    "        - Trích xuất đặc trưng(feature) từ ảnh hoặc feature maps trước đó \n",
    "        - Mỗi filter (kernel) học cách nhận biết các đặc điểm như cạnh, góc, nét cong,...\n",
    "        - Tạo ra feature maps – là biểu diễn không gian các đặc trưng tìm được\n",
    "    Trong LeNet:\n",
    "        - C1: Có 6 filters → 6 feature maps 28x28\n",
    "        - C3: Có 16 filters → 16 feature maps 10x10\n",
    "- `Subsampling/ Pooling` - Lớp gộp/ giảm mẫu\n",
    "    - Tác vụ:\n",
    "        - Giảm kích thước không gian của feature maps (ví dụ từ 28x28 → 14x14)\n",
    "        - Giúp mạng học nhanh hơn và giảm overfitting\n",
    "        - MaxPooling thường được dùng: chọn giá trị lớn nhất trong mỗi vùng nhỏ\n",
    "    - Trong LeNet:\n",
    "        - S2: 6 feature maps 14x14\n",
    "        - S4: 16 feature maps 5x5\n",
    "- `Fully Connected Layers` - Lớp kết nối đầy đủ:\n",
    "    - Tác vụ:\n",
    "        - Kết nối toàn bộ các giá trị đặc trưng trước đó với tất cả các neurons tiếp theo\n",
    "        - Thực hiện tổng hợp thông tin toàn cục để chuẩn bị phân loại\n",
    "        - Giống như \"não\" của mạng quyết định ảnh thuộc lớp nào\n",
    "    - Trong LeNet:\n",
    "        - F5: 120 neurons\n",
    "        - F6: 84 neurons\n",
    "- `Output layer` (10 neural) - Lớp output đầu ra:\n",
    "    - Tác vụ: \n",
    "        - Mỗi neuron tương ứng với một lớp phân loại (ví dụ 0 đến 9 nếu là nhận diện chữ số)\n",
    "        - Sau khi áp dụng Softmax, cho ra xác suất cho từng lớp\n",
    "        - Lớp nào có xác suất cao nhất → là kết quả dự đoán\n",
    " - `Feature Maps` - Bản đồ đặc trưng\n",
    "    - Tác vụ:\n",
    "        - Là kết quả của mỗi filter khi quét qua ảnh hoặc feature map trước đó\n",
    "        - Cho biết tại vị trí nào trong ảnh đang có đặc trưng cần tìm\n",
    "- `Gaussian connections` - Kết nối Gaussian\n",
    "    - Tác vụ: Trong LeNet gốc, không phải neuron nào trong lớp fully connected cũng kết nối với tất cả đầu vào. Chỉ kết nối theo mẫu “Gaussian” để tiết kiệm tài nguyên thời đó\n",
    "    - Ngày nay, ta thường dùng full connection thay vì kiểu kết nối này\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__() # 1 input channel, 6 ouput channel, nhân tích chập vuông 5x5\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # Một phép toán biến đổi: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16*5*5, 120) # 5*5 là chiều ảnh 5 pixel weight, 5 pixel height\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        # Lớp C1: 1 image input channel, 6 output channel\n",
    "        # Conv 5x5 sử dụng hàm kích hoạt ReLU\n",
    "        # Tensor output có size(N, 6, 28, 28), N là batch size\n",
    "        c1 = F.relu(self.conv1(input))\n",
    "        \n",
    "        # Lớp S2: Lấy mẫu có grid là 2x2, đây hoàn toàn là hàm chức năng\n",
    "        # Lớp này không có bất kỳ tham số nào, output tensor size(N, 6, 14, 14)\n",
    "        s2 = F.max_pool2d(c1, (2, 2))\n",
    "        \n",
    "        # Lớp C3: 6 input channel, 16 output channels\n",
    "        # 5x5 conv, dùng hàm kích hoạt ReLU \n",
    "        # Tensor output (N, 16, 10, 10)\n",
    "        c3 = F.relu(self.conv2(s2))\n",
    "        \n",
    "        # Lớp S4: Tương tự S2, tensor output (N, 16, 5, 5)\n",
    "        s4 = F.max_pool2d(c3, 2)\n",
    "        \n",
    "        # flatten: hàm thuần chức năng, chuyển matrix -> vector \n",
    "        # output tensor: (N, 400)\n",
    "        s4 = torch.flatten(s4, 1)\n",
    "        \n",
    "        # Lớp F5:tensor input (N, 400), tensor output (N, 120), sdung hàm ReLU\n",
    "        f5 = F.relu(self.fc1(s4))\n",
    "        \n",
    "        # Lớp F6: tensor input (N, 120), tensor output (N, 84), sdung hàm ReLu\n",
    "        f6 = F.relu(self.fc2(f5))\n",
    "        \n",
    "        # Lớp gaussian output: (N, 84) Tensor input, and tensor output(N, 10)\n",
    "        output = self.fc3(f6)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`max_pool` - làm giảm kích thước của dữ liệu đầu vào trong khi giữ lại các đặc trưng quan trọng. Giúp `giảm chi phí` và giảm `overfitting`\n",
    "\n",
    "Cách hoạt động:\n",
    "- Chia dữ liệu thành các cửa sổ nhỏ (windows): Mỗi cửa sổ là một khu vực con của dữ liệu đầu vào, ví dụ, một vùng 2x2 hoặc 3x3 của ảnh\n",
    "- Chọn giá trị lớn nhất trong mỗi cửa sổ: MaxPooling chọn giá trị lớn nhất trong mỗi cửa sổ và giữ lại nó, trong khi loại bỏ các giá trị còn lại\n",
    "- Lặp lại quá trình trên toàn bộ dữ liệu đầu vào: Điều này sẽ giúp giảm kích thước của dữ liệu (ví dụ, giảm chiều rộng và chiều cao của ảnh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta cần định nghĩa hàm forward, backward - nơi tính gradient sẽ tự động được định nghĩa bằng autograd. Ta có thể sdung bất kỳ phép toán Tensor nào trong hàm forward\n",
    "\n",
    "Các tham số có thể được học của model đc trả về bởi net.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size()) #conv1 weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lưu ý: kích thước đầu vào dự kiến ​​của lưới này (LeNet) là 32x32. Để sử dụng lưới này trên tập dữ liệu MNIST, ta phải thay đổi kích thước hình ảnh từ tập dữ liệu thành 32x32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0231, -0.0121, -0.1361, -0.1448, -0.1607, -0.0162,  0.0655, -0.0951,\n",
      "         -0.1019, -0.0271]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đặt các tham số và backprop về 0 và thực hiện gradient ngẫu nhiên:\n",
    "- Mục đích đặt lại để các tham số không bị cộng dồn qua mỗi lần gọi hàm backward()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad() # đặt lại gradient bằng 0\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- vì output không phải scalar nên khi thực hiện backward phải điền vào một một tensor ngẫu nhiên có shape giống với output (giá trị đc lấy mẫu từ pp chuẩn Gaussian với tb=0 và đlc=1) nó có tác dụng tính gradient lần đầu tiên trước trong quá trình backward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ghi chú:\n",
    "- torch.nn được thiết kế để xử lý dữ liệu theo batch\n",
    "- nếu ta chỉ có 1 sample, sử dụng input.unsqueeze(0) để kích hoạt batch fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input = torch.rand(3, 224, 224)  # 1 ảnh RGB\n",
    "# batch_input = input.unsqueeze(0)  # Thêm chiều batch -> [1, 3, 224, 224]\n",
    "# output = model(batch_input)       # Chạy được!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- số 0 đối số của `unsqueeze()` là vị trí của dim mới thêm vào batch. \n",
    "- unsqueeze(dim)\n",
    "\n",
    "    - dim=0: Thêm chiều batch ở đầu (ví dụ: [C, H, W] → [1, C, H, W]).\n",
    "\n",
    "    - dim=1: Thêm chiều ở vị trí thứ 1 (ví dụ: [C, H, W] → [C, 1, H, W]).\n",
    "\n",
    "    - dim=-1: Thêm chiều ở cuối (ví dụ: [C, H, W] → [C, H, W, 1])."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.Tensor` - Một mảng đa chiều trong PyTorch, hỗ trợ tính toán tự động (autograd) như phép `backward()`. Nó cũng lưu giữ gradient (độ dốc) liên quan đến tensor.\n",
    "\n",
    "`nn.Module` - Lớp cơ sở để xây dựng các mô-đun mạng nơ-ron. Cung cấp cách thuận tiện để đóng gói các tham số, với các tiện ích để chuyển chúng lên GPU, lưu/tải mô hình, v.v.\n",
    "\n",
    "`nn.Parameter` - Một loại Tensor đặc biệt, tự động được đăng ký là tham số của `Module` khi được gán làm thuộc tính của một `Module`.\n",
    "\n",
    "`autograd.Function` - Định nghĩa các phép toán tự động (forward/backward). Mỗi phép toán trên Tensor tạo ra ít nhất một nút Function, kết nối với các hàm đã tạo ra Tensor đó và ghi lại lịch sử tính toán."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LOSS FUNCTION`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Loss function` lấy cặp (output, target) và tính toán giá trị ước tính từ khoảng cách từ output đến target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8947, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)\n",
    "target = target.view(1, -1) # giống reshape\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giải thích tham số (1, -1)\n",
    "- 1: Đặt kích thước chiều đầu tiên (batch size) = 1\n",
    "→ Tạo 1 batch duy nhất chứa mẫu dữ liệu.\n",
    "\n",
    "- -1: PyTorch tự động tính toán chiều này dựa trên tổng số phần tử tensor.\n",
    "→ Công thức: `-1 = total_elements / other_dims`"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nếu ta theo loss hướng ngược lại, sử dụng thuộc tính `.grad_fn` của nó, ta sẽ thấy biểu đồ tính toán trông như sau:\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khi gọi `loss.backward()`, PyTorch sẽ tự động tính toán gradient (đạo hàm) cho tất cả các tham số trong mạng nơ-ron (các Tensor có `requires_grad=True`) và lưu giá trị gradient vào thuộc tính `.grad` của chúng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward0 object at 0x763714734760>\n",
      "<AddmmBackward0 object at 0x763714734760>\n",
      "<AccumulateGrad object at 0x76366c5dad40>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.next_functions` sẽ giúp ta đến các lớp (bước) trước trong đồ thị tính toán `computational graph`\n",
    "\n",
    "=> loss.grad_fn sẽ đưa ta đến node cuối cùng (`backward function`) trước output. Khi ta gọi `.next_functions` nó sẽ đưa ta về bước trước đó là linear và tiếp tục là relu và nữa thì là linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BACKPROP` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Backprop` - thuật toán lan truyền ngược để cập nhật các trọng số (weights) trong mạng neural trong khi train.\n",
    "\n",
    "Để `lan truyền ngược` thì ta chỉ cần sử dụng `loss.backward()`. \n",
    "- `Note`: ta phải xóa các `gradient` hiện có nếu không gradient sẽ đuợc tích lũy vào gradient hiện có."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "None\n",
      "conv1.bias.grad after backward\n",
      "tensor([-0.0022, -0.0037,  0.0091, -0.0083,  0.0075, -0.0028])\n"
     ]
    }
   ],
   "source": [
    "# Ta xét một vd gradient của conv1 trước/ sau khi backward\n",
    "net.zero_grad() # Xóa các gradient\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward() # Hàm sẽ tính các gradient của tham số dựa trên loss_func\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Giải thích chi tiết từng bước thực hiện`:\n",
    "\n",
    "`Trước khi gọi backward` - Vì ta chưa tính gradient => `net.conv1.bias.grad` là None (Do Pytorch không tự động tính gradient trừ khi ta yêu cầu qua `backward()`)\n",
    "- `net.zero_grad()`: được gọi để reset các giá trị gradient => trành cộng dồn các gradient (cũ + mới)\n",
    "\n",
    "`Khi gọi backward` - Pytorch sẽ tính gradient của loss với tất cả các tham số của models (weight, bias của tất cả các lớn). Quá trình này đi ngược từ loss về các lớp trước đó trong mạng và tính toán gradient cho mỗi tham số theo `chain-rule`\n",
    "- gradient sẽ được lưu vào các `thuộc tính grad` của các tham số tương ứng với models\n",
    "- Sau khi `backward()` được ta sẽ nhìn thấy các giá trị gradient trong `conv1.bias.grad` - nơi chứa gradient bias của lớp conv1 (muốn coi lớp nào thì gọi lớp đó)\n",
    "\n",
    "`Sau khi gọi backward` - sau khi `loss.backward()` đuợc gọi thì các gradient cho các tham số của lớp conv1 sẽ được sẽ được tính toán và lưu trong conv1.bias.grad\n",
    "- Khi ta gọi để hiển thị thì ta nhận được giá trị thực tế của gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`UPDATE WEIGHTS` - Quy tắc cập nhật đơn giản nhất được sử dụng trong thực tế là SGD (`Stochastic Gradient Descent`)\n",
    "\n",
    "`weight = weight - learning_rate * gradient`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GIẢI THÍCH`\n",
    "\n",
    "`learning_rate = 0.01` - quyết định mức độ thay đổi của các tham số trong mỗi bước huấn luyện,`lr = 0.01` có nghĩa mỗi lần cập nhật trọng số thì gradient sẽ nhân với lr để điều chỉnh trọng số một cách chậm hơn\n",
    "\n",
    "`for f in net.parameters():` \n",
    "- net.parameters() trả về tất cả các tham số của mô hình trong mạng `net`\n",
    "- `f` là từng tham số trọng mạng\n",
    "\n",
    "=> Duyệt qua từng tham số trong mô hình để thực hiện việc `update weight`\n",
    "\n",
    "`f.data.sub_(f.grad.data * learning_rate)` - là nơi thực hiện việc `update weight`\n",
    "- `f.data`: đây là giá trị thực tế của tham số f. `.data` là một cách để truy cập giá trị thực của tensor mà không yêu cầu tính toán gradient \n",
    "- `f.grad.data`: đây là gradient của tham số f. Gradient cho biết mức độ thay đổi cần thiết của tham số f để giảm thiểu loss. Gradient này đã được tính toán khi gọi loss.backward()\n",
    "- `.sub_()`: sẽ trừ đi giá trị của biểu thức bên phải từ giá trị hiện tại của f.data vì sub_() là phương thức in_place, nó sẽ cập nhật giá trị của f.data ngay lập tức"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*`in-place` - là phương thức mà khi ta thao tác trực tiếp trên dữ liệu đầu vào mà `không cần thêm bộ nhớ phụ đáng kể`. Thay vì tạo ra bản sao của dữ liệu mới thì nó `thay đổi trực tiếp dữ liệu gốc`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khi ta tối ưu mạng neural thì không chỉ có cách `update weight` đơn giản như trên mà là các quy tắc cập nhật khác nhau: `SGD`, `Nesterov-SGD`, `Adam`, `RMSProp`, ...\n",
    "\n",
    "=> Pytorch có package để triển khai các phương pháp này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "optimizer.zero_grad() \n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GIẢI THÍCH`\n",
    "\n",
    "`optimizer = optim.SGD(net.parameters(), lr=0.01)`\n",
    "- `optimizer`: là một đối tượng tối ưu hóa, được sử dụng để cập nhật trọng số của mô hình trong quá trình train\n",
    "- `optim.SGD`: là cách để tạo ra Stochastic Gradient Descent optimizer\n",
    "- `net.parameters()`: Đây là các tham số  của mô hình\n",
    "    - `net`: Bạn cung cấp các tham số này cho optimizer để optimizer có thể cập nhật chúng trong quá trình train\n",
    "    - `lr=0.01`: Đây là learning rate (tỷ lệ học), quyết định mức độ thay đổi của các tham số trong mỗi lần cập nhật\n",
    "\n",
    "`optimizer.zero_grad()` - Vì pytorch không tự động được xóa giữa các lần cập nhật\n",
    "\n",
    "=> ta phải gọi `.zero_grad()` để đặt lại các gradient trước khi tính toán mới => tránh cộng dồn \n",
    "\n",
    "`output = net(input)` - buớc forward để đưa ra một dự đoán từ net\n",
    "\n",
    "`loss = criterion(output, target)` - tính toán hàm loss giữa đầu ra mô hình và giá trị thực tế. Hàm này đo lường sự sai lechj giữa output và target\n",
    "\n",
    "`loss.backward()` - gọi phương thức này để tính toán các gradient của các tham số trong mô hình đối với loss. Sau khi gọi `loss.backward()' thì các gradient sẽ được tính toán tự động thông qua quá trình lan truyền ngược và lưu vào .grad của các tham số trong mô hình.\n",
    "\n",
    "`optimizer.step()` - sau các bước tính toán thì ta gọi để  `update weight` cho models. Optimizer sẽ dùng các gradient và lr đã cho để thực hiện việc cập nhật các tham số sao cho giảm thiểu loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
