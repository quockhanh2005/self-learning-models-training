{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 36px; color: #FFD700\">5 - BUILD the NEURAL NETWORK</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Không gian tên torch.nn cung cấp tất cả các khối xây dựng mạng nơ-ron. Mỗi mô-đun trong PyTorch đều là lớp con của nn.Module . Mạng nơ-ron là một mô-đun bao gồm các mô-đun khác (lớp). Cấu trúc lồng nhau này cho phép xây dựng và quản lý các kiến ​​trúc phức tạp một cách dễ dàng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Device -  có thể đào tạo mô hình của mình trên một accelerator như CUDA, MPS, MTIA hoặc XPU. Nếu bộ tăng tốc hiện tại khả dụng, chúng tôi sẽ sử dụng nó. Nếu không, chúng tôi sẽ sử dụng CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define - class: phân lớp nn.Module và khởi tạo các lớp mạng nơ-ron trong __init__. Mỗi lớp con nn.Module thực hiện các thao tác trên dữ liệu đầu vào trong phương thức forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tạo một models thể hiện của Neural network và chuyển nó đến device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để dùng mô hình, ta chuyển tiếp cho nó dữ liệu đầu vào. Điều này thực thi mô hình forward cùng với một số hđ nền. Không gọi forward trực tiếp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gọi mô hình trên đầu vào trả về một tensor 2 chiều với dim=0 tương ứng với mỗi đầu ra của 10 giá trị dự đoán thô cho mỗi lớp và dim=1 tương ứng với các giá trị riêng lẻ của mỗi đầu ra.\n",
    "- ảnh ngẫu nhiên có size 28*28, batch__size = 1 (có 1 ảnh đầu vào)\n",
    "- dim = 0 trục dọc -> mỗi hàng một mẫu ảnh \n",
    "- dim = 1 trục ngang -> mỗi cột là giá trị cho một lớp (0 - 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta có được xác suất dự đoán bằng cách truyền nó qua một thể hiện của module nn.Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([2], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_prob = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_prob.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# lấy một minibatch gồm 3 hình ảnh có kích thước 28x28\n",
    "input_image = torch.rand(3, 28, 28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Flatten để chuyển đổi hình 2D thành một mảng liền kề gồm 784 giá trị pixel - kích thước minibatch tại dum = 0 được duy trì "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Linear - áp dụng biến đổi tuyến tính vào đầu vào bằng cách sdung trọng số và độ lệch được lưu trữ của nó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.ReLU kích hoạt phi tuyến tính tạo ra các ánh xạ giữa các đầu vào và đầu ra của mô hình. Chúng được áp dụng sau các phép biến đổi tuyến tính để đưa vào tính phi tuyến tính giúp mạng neural học được nhiều hiện tượng khác nhau. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLu: tensor([[ 0.4186,  0.3890, -0.2776, -0.2148,  0.0639,  0.0667,  0.4413,  0.1873,\n",
      "         -0.0813, -0.0056,  0.4241,  0.3613,  0.0495, -0.1898, -0.3598, -0.4590,\n",
      "          0.4191,  0.4478, -0.0819, -0.1512],\n",
      "        [ 0.1971,  0.4311, -0.1787,  0.0085,  0.3031,  0.1306,  0.8370,  0.3507,\n",
      "          0.1357,  0.3999,  0.6399, -0.0217,  0.3160, -0.3835,  0.1261, -0.3442,\n",
      "          0.3675,  0.4035,  0.1043,  0.0423],\n",
      "        [ 0.0811,  0.5748, -0.1728,  0.0425, -0.0480,  0.0639,  0.8966,  0.1570,\n",
      "         -0.1531, -0.0447,  0.4791,  0.4385,  0.1223, -0.2272, -0.1948, -0.3357,\n",
      "          0.3031, -0.0743,  0.2906, -0.0082]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.4186, 0.3890, 0.0000, 0.0000, 0.0639, 0.0667, 0.4413, 0.1873, 0.0000,\n",
      "         0.0000, 0.4241, 0.3613, 0.0495, 0.0000, 0.0000, 0.0000, 0.4191, 0.4478,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1971, 0.4311, 0.0000, 0.0085, 0.3031, 0.1306, 0.8370, 0.3507, 0.1357,\n",
      "         0.3999, 0.6399, 0.0000, 0.3160, 0.0000, 0.1261, 0.0000, 0.3675, 0.4035,\n",
      "         0.1043, 0.0423],\n",
      "        [0.0811, 0.5748, 0.0000, 0.0425, 0.0000, 0.0639, 0.8966, 0.1570, 0.0000,\n",
      "         0.0000, 0.4791, 0.4385, 0.1223, 0.0000, 0.0000, 0.0000, 0.3031, 0.0000,\n",
      "         0.2906, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Dùng hàm kích hoạt để đưa tính phi tuyến vào mô hình\n",
    "print(f\"Before ReLu: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Sequential là một container có thứ tự của các module. Dữ liệu được truyền qua tất cả các module theo cùng thứ tự như đã xác định. Ta có thể dùng các container tuần tự để tạo thành một mạng nhanh như seq_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ") # Đang hiển thị 2 lớp học\n",
    "input_image = torch.rand(3, 28, 28)\n",
    "logits = seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Softmax - lớp linear cuối cùng trả về logit được truyền đến module nn.Softmax. Logit được chia tỷ lệ thành các giá trị [0, 1] biễu diễn xs dự đoán của mô hình có từng lớp. dim là tham số chỉ ra chiều mà các giá trị tổng phải bằng 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_prob = softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Một lớp mạng neural được tham số hóa - weights + bias có thể học được. Những tham số này được tối ưu hóa trong quá trình huấn luyện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values: tensor([[-0.0096,  0.0243,  0.0113,  ...,  0.0034,  0.0095,  0.0169],\n",
      "        [ 0.0265, -0.0235,  0.0126,  ..., -0.0067, -0.0331,  0.0336]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values: tensor([-0.0010,  0.0065], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values: tensor([[-0.0299, -0.0352,  0.0060,  ...,  0.0153,  0.0371, -0.0375],\n",
      "        [-0.0248,  0.0043,  0.0391,  ..., -0.0256,  0.0054,  0.0216]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values: tensor([-0.0363, -0.0157], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values: tensor([[-2.2874e-02, -4.3611e-05, -3.9551e-02,  ..., -4.9313e-03,\n",
      "          2.5919e-02,  1.3836e-02],\n",
      "        [ 4.1810e-02, -2.9150e-02, -3.8519e-02,  ..., -3.0269e-02,\n",
      "          2.9247e-02,  8.5807e-04]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values: tensor([-0.0369, -0.0398], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values: {param[:2]} \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
