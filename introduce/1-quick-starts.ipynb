{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 36px; color: #FFD700\">1 - QUICKSTART</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch có 2 nguyên hàm để làm việc với dữ liệu\n",
    "- torch.utils.data.DataLoader - bọc một đối tượng có thể lặp lại xung quanh Dataset\n",
    "- torch.utils.data.Dataset - lưu trữ mẫu và nhãn tướng ứng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset là một iterable - đối tượng lặp đi lặp lại, bọc quanh 1 đối tượng có nghĩa là Dataset có thể lặp qua từng mẫu bằng tay. Điều này không hiệu quả nên Dataloader sẽ thực hiện thay tự động và thông minh hơn.\n",
    "\n",
    "- Tự động chia thành batch\n",
    "- Shuffle nếu muốn\n",
    "- Tải song song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- import torch - Tải PyTorch\n",
    "\n",
    "- from torch import nn - Chứa các công cụ để xây dựng mạng nơ-ron\n",
    "\n",
    "- from torch.utils.data import DataLoader - Giúp chia dữ liệu thành các batch nhỏ, có thể shuffle và load song song\n",
    "\n",
    "- from torchvision import datasets -  Import tập các dataset hình ảnh phổ biến\n",
    "\n",
    "- from torchvision.transforms import ToTensor - Một phép biến đổi ảnh từ định dạng bình thường (PIL/NumPy) sang tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cung cấp các thư viện riêng cho từng miền: TorchText, TorchVision, TorchAudio chứa các dataset. Hướng dẫn này tập trung vào TorchVision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mỗi TorchVision Datasets bao gồm 2 đối số: transform và target_transform để sửa mẫu và nhãn tương ứng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# Tải dữ liệu huấn luyện từ datasets\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\", # thư mục chứa dữ liệu tải về\n",
    "    train=True, # train = true là ta tải tập train và tập test = False\n",
    "    download=True, # tải từ internet nếu chưa có dataset\n",
    "    transform=ToTensor() # chuyển ảnh thành tensor pytorch\n",
    ")\n",
    "\n",
    "# Tải tập test\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ảnh gốc trong dataset là định dạng PIL Image. \n",
    "\n",
    "ToTensor() trong trường hợp này:\n",
    "- Chuyển ảnh thành Tensor Pytorch\n",
    "- Scale pixel từ [0, 255] -> [0.0, 1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_size = 64 nghĩa mỗi phần tử iterable dataloader sẽ trả về 1 batch gồm 64 feature và labels - ở đây là 64 tấm ảnh và nhãn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Truyền Dataset vào Dataloader\n",
    "batch_size = 64 # số mẫu trên mỗi batch\n",
    "\n",
    "# Create data loaders\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size) \n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader: # mỗi vòng lặp trả ra X; 64 ảnh, y 64 nhãn\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloader:\n",
    "- Tự động chia thành từng bacth gồm 64 tấm ảnh\n",
    "- trả về (ảnh, nhãn) ở mỗi lần lặp\n",
    "- có thể shuffle (shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X.shape:\n",
    "- N: batch size - 64\n",
    "- C: kênh ảnh - 1 kênh đen/trắng\n",
    "- H: chiều cao ảnh - 28\n",
    "- W - chiều rộng ảnh - 28 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y.shape: trả về số nhãn là kiểu số nguyên type torch.int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để định nghĩa mạng neural ta sẽ tạo lớp kế thừa từ nn.Module. Để tăng tốc, ta di chuyển nó đến accelerator - bộ tăng tốc. Nếu nó không khả dụng thì dùng CPU.\n",
    "- Tạo lớp kế thừa từ nn.Module, đn các lớp của mạng trong hàm __init__\n",
    "- Chỉ định cách dữ liệu đi qua trong hàm forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ktra thiết bị\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# định nghĩa models\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self): # Khởi tạo\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten() # Chuyển từ ảnh 2D -> vector 1D\n",
    "        self.linear_relu_stack = nn.Sequential( # xếp chồng các lớp liên tiếp\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x): # đn các dữ liệu đi qua mạng\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x) # chạy qua từng lớp đã khai báo\n",
    "        return logits # đầu ra chưa chuẩn hóa -> dùng tính loss (vector 10 chiều)\n",
    "    \n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Sequential() để xếp chồng các lớp liên tiếp.\n",
    "- Linear: lớp học có trọng số (fully connected layer)\n",
    "- ReLU(): hàm kích hoạt để tạo phi tuyến tính, ReLu sẽ tính giá trị đầu ra của mỗi node trước khi truyền sang lớp tiếp theo\n",
    "- output là 10 lớp (phân loại 10 loại quần áo)\n",
    "\n",
    "Cách biến đổi từng vector ở từng lớp ví dụ 784 -> 512: Ta sẽ dùng phép nhân ma trận: output = input @ W.T + b\n",
    "- input: [batch_size, 784]\n",
    "- W: trọng số, kích thước [512, 784]\n",
    "- b: vector bias [512].\n",
    "\n",
    "Ta sẽ dùng 784 input với một bộ weight cho từng node tính từng node như vậy đến khi hết 512 node là ta sẽ có được một lớp vector 512 node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để tối ưu hóa thì ta cần một hàm mất mát và một trình tối ưu hóa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CrossEntropyLoss được dùng cho phân loại nhiều lớp\n",
    "- Đầu ra là logits chưa qua softmax \n",
    "- Nhãn đầu ra là chỉ số class(0, 1, 2, ..., 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.optim.SGD(...)\n",
    "SGD = Stochastic Gradient Descent\n",
    "\n",
    "Là phương pháp cập nhật trọng số mô hình dựa trên đạo hàm (gradient) của loss\n",
    "\n",
    "- model.parameters()\n",
    "Truyền vào tất cả các tham số học được của mô hình (weights và biases)\n",
    "\n",
    "Optimizer sẽ tự động biết phải cập nhật những gì\n",
    "\n",
    "- lr=1e-3\n",
    "Learning rate = 0.001\n",
    "\n",
    "Tốc độ cập nhật trọng số\n",
    "\n",
    "Nhỏ quá → học chậm\n",
    "\n",
    "Lớn quá → học không ổn định"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train() # chuyển sang chế độ train\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device) # đưa dữ liệu vào thiết bị\n",
    "        \n",
    "        pred = model(X) # truyền X vào mô hình để dự đoán\n",
    "        loss = loss_fn(pred, y) # trả ra giá trị loss\n",
    "        \n",
    "        loss.backward() # tính grad, bước lan truyền ngược trong BP\n",
    "        optimizer.step() # dựa vào grad vừa tính và cập nhật vào models -. giảm loss\n",
    "        optimizer.zero_grad() # xóa -> grad cũ nếu không sẽ bị cộng dồn qua mỗi batch\n",
    "        \n",
    "        if batch % 100 == 0: # in loss sau mỗi 100 batch\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "size dùng để in tiến độ huấn luyện \n",
    "\n",
    "model.train(): phải bật vì Dropout, BatchNorm sẽ hđ khác khi train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval() # chuyển mô hình sang chế độ đánh giá\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad(): # tắt grad\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device) # đưa vào device để tăng hiệu suất\n",
    "            pred = model(X) # logits đầu ra từ models\n",
    "            test_loss += loss_fn(pred, y).item() # tính loss của từng bathc rồi cộng dồn\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()  # Tính số mẫu dự đoán đúng\n",
    "    \n",
    "    # Tính AVG loss & accuracy\n",
    "    test_loss /= num_batches \n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.eval(): bắt buộc khi đánh giá mô hình, tắt các chức năng chỉ dùng huấn luyện như Dropout, BatchNorm, ...\n",
    "\n",
    "with torch.no_grad(): không tính grad\n",
    "- không cần BP khi test\n",
    "- tiết kiệm được bộ nhớ và tăng tốc độ \n",
    "\n",
    "-> chỉ cần tính loss để so sánh chứ không cần cập nhật lại mô hình "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.631856 [   64/60000]\n",
      "loss: 0.732025 [ 6464/60000]\n",
      "loss: 0.505270 [12864/60000]\n",
      "loss: 0.749367 [19264/60000]\n",
      "loss: 0.668971 [25664/60000]\n",
      "loss: 0.638996 [32064/60000]\n",
      "loss: 0.725437 [38464/60000]\n",
      "loss: 0.716660 [44864/60000]\n",
      "loss: 0.704364 [51264/60000]\n",
      "loss: 0.673693 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.662718 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.610344 [   64/60000]\n",
      "loss: 0.712576 [ 6464/60000]\n",
      "loss: 0.489044 [12864/60000]\n",
      "loss: 0.736095 [19264/60000]\n",
      "loss: 0.657228 [25664/60000]\n",
      "loss: 0.627645 [32064/60000]\n",
      "loss: 0.707528 [38464/60000]\n",
      "loss: 0.706812 [44864/60000]\n",
      "loss: 0.693376 [51264/60000]\n",
      "loss: 0.659354 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.648738 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.590750 [   64/60000]\n",
      "loss: 0.694575 [ 6464/60000]\n",
      "loss: 0.474397 [12864/60000]\n",
      "loss: 0.723791 [19264/60000]\n",
      "loss: 0.646676 [25664/60000]\n",
      "loss: 0.617635 [32064/60000]\n",
      "loss: 0.690840 [38464/60000]\n",
      "loss: 0.698173 [44864/60000]\n",
      "loss: 0.683697 [51264/60000]\n",
      "loss: 0.645799 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.635888 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.572891 [   64/60000]\n",
      "loss: 0.678009 [ 6464/60000]\n",
      "loss: 0.461157 [12864/60000]\n",
      "loss: 0.712463 [19264/60000]\n",
      "loss: 0.637060 [25664/60000]\n",
      "loss: 0.608786 [32064/60000]\n",
      "loss: 0.675512 [38464/60000]\n",
      "loss: 0.690690 [44864/60000]\n",
      "loss: 0.675236 [51264/60000]\n",
      "loss: 0.632991 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.624076 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.556591 [   64/60000]\n",
      "loss: 0.662791 [ 6464/60000]\n",
      "loss: 0.449136 [12864/60000]\n",
      "loss: 0.701996 [19264/60000]\n",
      "loss: 0.628324 [25664/60000]\n",
      "loss: 0.600901 [32064/60000]\n",
      "loss: 0.661325 [38464/60000]\n",
      "loss: 0.684294 [44864/60000]\n",
      "loss: 0.668030 [51264/60000]\n",
      "loss: 0.620923 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.613215 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.541657 [   64/60000]\n",
      "loss: 0.648752 [ 6464/60000]\n",
      "loss: 0.438234 [12864/60000]\n",
      "loss: 0.692290 [19264/60000]\n",
      "loss: 0.620272 [25664/60000]\n",
      "loss: 0.593776 [32064/60000]\n",
      "loss: 0.648257 [38464/60000]\n",
      "loss: 0.678977 [44864/60000]\n",
      "loss: 0.661851 [51264/60000]\n",
      "loss: 0.609417 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.603225 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.527965 [   64/60000]\n",
      "loss: 0.635839 [ 6464/60000]\n",
      "loss: 0.428327 [12864/60000]\n",
      "loss: 0.683196 [19264/60000]\n",
      "loss: 0.612673 [25664/60000]\n",
      "loss: 0.587280 [32064/60000]\n",
      "loss: 0.636267 [38464/60000]\n",
      "loss: 0.674697 [44864/60000]\n",
      "loss: 0.656548 [51264/60000]\n",
      "loss: 0.598423 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.594049 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.515338 [   64/60000]\n",
      "loss: 0.624028 [ 6464/60000]\n",
      "loss: 0.419222 [12864/60000]\n",
      "loss: 0.674636 [19264/60000]\n",
      "loss: 0.605519 [25664/60000]\n",
      "loss: 0.581450 [32064/60000]\n",
      "loss: 0.625240 [38464/60000]\n",
      "loss: 0.671282 [44864/60000]\n",
      "loss: 0.652072 [51264/60000]\n",
      "loss: 0.587858 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.585617 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.503663 [   64/60000]\n",
      "loss: 0.613215 [ 6464/60000]\n",
      "loss: 0.410793 [12864/60000]\n",
      "loss: 0.666593 [19264/60000]\n",
      "loss: 0.598745 [25664/60000]\n",
      "loss: 0.575956 [32064/60000]\n",
      "loss: 0.615084 [38464/60000]\n",
      "loss: 0.668684 [44864/60000]\n",
      "loss: 0.648219 [51264/60000]\n",
      "loss: 0.577782 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.577861 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.492791 [   64/60000]\n",
      "loss: 0.603260 [ 6464/60000]\n",
      "loss: 0.402949 [12864/60000]\n",
      "loss: 0.659043 [19264/60000]\n",
      "loss: 0.592237 [25664/60000]\n",
      "loss: 0.570768 [32064/60000]\n",
      "loss: 0.605819 [38464/60000]\n",
      "loss: 0.666823 [44864/60000]\n",
      "loss: 0.644889 [51264/60000]\n",
      "loss: 0.568146 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.570709 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.482649 [   64/60000]\n",
      "loss: 0.594091 [ 6464/60000]\n",
      "loss: 0.395713 [12864/60000]\n",
      "loss: 0.651925 [19264/60000]\n",
      "loss: 0.585941 [25664/60000]\n",
      "loss: 0.565853 [32064/60000]\n",
      "loss: 0.597346 [38464/60000]\n",
      "loss: 0.665525 [44864/60000]\n",
      "loss: 0.641994 [51264/60000]\n",
      "loss: 0.558851 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.564103 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.473148 [   64/60000]\n",
      "loss: 0.585633 [ 6464/60000]\n",
      "loss: 0.388999 [12864/60000]\n",
      "loss: 0.645223 [19264/60000]\n",
      "loss: 0.579773 [25664/60000]\n",
      "loss: 0.561078 [32064/60000]\n",
      "loss: 0.589559 [38464/60000]\n",
      "loss: 0.664756 [44864/60000]\n",
      "loss: 0.639420 [51264/60000]\n",
      "loss: 0.549911 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.557993 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.464198 [   64/60000]\n",
      "loss: 0.577829 [ 6464/60000]\n",
      "loss: 0.382737 [12864/60000]\n",
      "loss: 0.638918 [19264/60000]\n",
      "loss: 0.573749 [25664/60000]\n",
      "loss: 0.556447 [32064/60000]\n",
      "loss: 0.582398 [38464/60000]\n",
      "loss: 0.664415 [44864/60000]\n",
      "loss: 0.637052 [51264/60000]\n",
      "loss: 0.541261 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.552335 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.455732 [   64/60000]\n",
      "loss: 0.570601 [ 6464/60000]\n",
      "loss: 0.376876 [12864/60000]\n",
      "loss: 0.632882 [19264/60000]\n",
      "loss: 0.567882 [25664/60000]\n",
      "loss: 0.551942 [32064/60000]\n",
      "loss: 0.575761 [38464/60000]\n",
      "loss: 0.664344 [44864/60000]\n",
      "loss: 0.634817 [51264/60000]\n",
      "loss: 0.532879 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.547076 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.447767 [   64/60000]\n",
      "loss: 0.563912 [ 6464/60000]\n",
      "loss: 0.371375 [12864/60000]\n",
      "loss: 0.627078 [19264/60000]\n",
      "loss: 0.562133 [25664/60000]\n",
      "loss: 0.547467 [32064/60000]\n",
      "loss: 0.569641 [38464/60000]\n",
      "loss: 0.664566 [44864/60000]\n",
      "loss: 0.632723 [51264/60000]\n",
      "loss: 0.524857 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.542188 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.440219 [   64/60000]\n",
      "loss: 0.557718 [ 6464/60000]\n",
      "loss: 0.366266 [12864/60000]\n",
      "loss: 0.621507 [19264/60000]\n",
      "loss: 0.556552 [25664/60000]\n",
      "loss: 0.543106 [32064/60000]\n",
      "loss: 0.563946 [38464/60000]\n",
      "loss: 0.664945 [44864/60000]\n",
      "loss: 0.630755 [51264/60000]\n",
      "loss: 0.517113 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.537634 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.433069 [   64/60000]\n",
      "loss: 0.551988 [ 6464/60000]\n",
      "loss: 0.361455 [12864/60000]\n",
      "loss: 0.616124 [19264/60000]\n",
      "loss: 0.551083 [25664/60000]\n",
      "loss: 0.538832 [32064/60000]\n",
      "loss: 0.558696 [38464/60000]\n",
      "loss: 0.665463 [44864/60000]\n",
      "loss: 0.628881 [51264/60000]\n",
      "loss: 0.509724 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.533385 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.426281 [   64/60000]\n",
      "loss: 0.546704 [ 6464/60000]\n",
      "loss: 0.356876 [12864/60000]\n",
      "loss: 0.610966 [19264/60000]\n",
      "loss: 0.545726 [25664/60000]\n",
      "loss: 0.534618 [32064/60000]\n",
      "loss: 0.553838 [38464/60000]\n",
      "loss: 0.666049 [44864/60000]\n",
      "loss: 0.627094 [51264/60000]\n",
      "loss: 0.502654 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.529409 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.419771 [   64/60000]\n",
      "loss: 0.541781 [ 6464/60000]\n",
      "loss: 0.352538 [12864/60000]\n",
      "loss: 0.606020 [19264/60000]\n",
      "loss: 0.540444 [25664/60000]\n",
      "loss: 0.530484 [32064/60000]\n",
      "loss: 0.549315 [38464/60000]\n",
      "loss: 0.666563 [44864/60000]\n",
      "loss: 0.625355 [51264/60000]\n",
      "loss: 0.495929 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.525682 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.413552 [   64/60000]\n",
      "loss: 0.537197 [ 6464/60000]\n",
      "loss: 0.348464 [12864/60000]\n",
      "loss: 0.601211 [19264/60000]\n",
      "loss: 0.535264 [25664/60000]\n",
      "loss: 0.526438 [32064/60000]\n",
      "loss: 0.545084 [38464/60000]\n",
      "loss: 0.667051 [44864/60000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m-------------------------------\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     test(test_dataloader, model, loss_fn)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDone!\u001b[39m\u001b[33m\"\u001b[39m) \n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(dataloader, model, loss_fn, optimizer)\u001b[39m\n\u001b[32m      2\u001b[39m size = \u001b[38;5;28mlen\u001b[39m(dataloader.dataset)\n\u001b[32m      3\u001b[39m model.train() \n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# đưa dữ liệu vào thiết bị\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# truyền X vào mô hình để dự đoán\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/python/python_programming/pytorch/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/python/python_programming/pytorch/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/python/python_programming/pytorch/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/python/python_programming/pytorch/.venv/lib/python3.12/site-packages/torchvision/datasets/mnist.py:143\u001b[39m, in \u001b[36mMNIST.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    139\u001b[39m img, target = \u001b[38;5;28mself\u001b[39m.data[index], \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m.targets[index])\n\u001b[32m    141\u001b[39m \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[32m    142\u001b[39m \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m img = \u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mL\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    146\u001b[39m     img = \u001b[38;5;28mself\u001b[39m.transform(img)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/python/python_programming/pytorch/.venv/lib/python3.12/site-packages/PIL/Image.py:3303\u001b[39m, in \u001b[36mfromarray\u001b[39m\u001b[34m(obj, mode)\u001b[39m\n\u001b[32m   3301\u001b[39m shape = arr[\u001b[33m\"\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   3302\u001b[39m ndim = \u001b[38;5;28mlen\u001b[39m(shape)\n\u001b[32m-> \u001b[39m\u001b[32m3303\u001b[39m strides = \u001b[43marr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrides\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3304\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3305\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "epochs = 20 # train theo epochs \n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vì 1 epoch chưa đủ để mô hình học tốt: Mỗi lần đi qua toàn bộ dữ liệu (1 epoch), mô hình chỉ học được một phần mối quan hệ giữa dữ liệu và nhãn.\n",
    "\n",
    "Cần lặp đi lặp lại nhiều lần (epoch) để:\n",
    "\n",
    "- Tối ưu tốt hơn\n",
    "\n",
    "- Trọng số điều chỉnh dần dần\n",
    "\n",
    "- Mô hình học được xu hướng sâu hơn\n",
    "\n",
    "SGD là một thuật toán cập nhật dần từng bước dựa trên mini-batch, nên cần nhiều epoch để hội tụ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cách hoạt động:\n",
    "Mỗi epoch, bạn theo dõi loss / accuracy trên test set\n",
    "\n",
    "Nếu thấy:\n",
    "\n",
    "- Accuracy không tăng nữa\n",
    "\n",
    "- Hoặc loss không giảm nữa\n",
    "\n",
    "- Hoặc bắt đầu overfitting (loss tăng trên test set)\n",
    "→ Dừng lại sớm để tiết kiệm thời gian và tránh overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "# Lưu models đã train xong Accuracy: 81.5%, AVG loss: 0.525682\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load models từ file weights\n",
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
